第五章、存储器管理

存储器是一种宝贵而又稀缺的资源。如何对它加以有效管理，不仅直接影响存储器的利用率，而且对系统性能也有重大影响。存储器管理的主要对象是内存。由于对外存的管理与对内存的管理相类似，只是它们的用途不同，即外存主要用于存放文件，因此本书把对外存的管理放在第8章（文件管理）中进行介绍。本章知识导图如图5-1所示。

![](assets/5-1.png)

[toc]

# 1. 存储器的层次结构

计算机在执行指令时，几乎每条指令都会涉及对存储器的访问
- 因此要求计算机对存储器的访问速度能跟得上处理机的运行速度
- 此外还要求存储器具有非常大的容量
- 而且存储器的价格还应很便宜。
对于上述十分严格的3个要求，目前是无法同时满足的。因此在现代计算机系统中，都无一例外地采用了多层结构的存储器。

## 1.1 多层结构的存储器

### 1.1.1 存储器的多层结构

对于通用计算机而言，存储层次至少应具有3层：
- 最高层: CPU寄存器
- 中间层: 主存储器
- 最低层: 辅助存储器（简称辅存）

在较高档的计算机中，还可以根据具体的功能分工，将存储层次细分为
- 寄存器
- 高速缓存
- 主存储器
- 磁盘缓存
- 固定磁盘
- 可移动存储介质

如图5r2所示，在存储层次中，层次越高（越靠近CPU），存储介质的访问速度越快，价格也越高，所配置的存储容量也越小。
- 其中，寄存器、高速缓存、主存储器和磁盘缓存，均属于OS存储管理的管辖范畴，断电后它们所存储的信息将不再存在。
- 而低层的固定磁盘和可移动存储介质，则属于设备管理的管辖范畴，它们所存储的信息会被长期保存。

![](assets/5-2.png)


### 1.1.2 可执行存储器

寄存器和主存储器又被称为可执行存储器。对于存放在其中的信息，与存放在辅存中的信息相比而言，计算机所采用的访问机制是不同的，所须耗费的时间也是不同的。
- 进程可以在很少的时钟周期内使用一条load或store指令对可执行存储器进行访问
- 但对辅存的访问则需要通过I/O设备实现。
因此，在访问中将涉及中断、设备驱动程序以及物理设备的运行，所须耗费的时间远远高于对可执行存储器访问的时间
> 一般会相差3个数量级甚至更多。

不同层次的存储介质会由OS进行统一管理。
- OS的存储管理会负责对可执行存储器进行分配与回收
- 以及向其提供在不同存储层次间数据移动的管理机制，如主存储器与磁盘缓存、高速缓存与主存储器间的数据移动等。
- 而在设备和文件管理中，OS则会根据用户的需求，对辅存提供管理机制。

本章主要讨论有关主存储器管理部分的问题，针对辅存管理问题，本书将会在第9章中进行介绍。

## 1.2 主存储器和寄存器

### 1.2.1 主存储器

主存储器，简称主存或内存，也称为可执行存储器，是计算机系统中的主要部件，用于保存进程运行时的程序和数据。

通常，处理机都会从内存中取得指令和数据，并将其所取得的指令放入指令寄存器中，而将其所读取的数据装入数据寄存器中，或者进行相反操作，即将寄存器中的数据存入内存。

早期的内存是由磁芯做成的，其容量一般为数十KB到数百KB。随着VLSI(Very Large Scale Intergration,超大规模集成电路)的发展，现在的内存已由VLSI构成，即使是微机系统，其容量也在数十MB到数GB，而且还在不断增加。而嵌入式计算机系统则一般仅有几十KB到几MB。

CPU与外围设备交换的信息，一般也会依托于内存的地址空间。由于内存的访问速度远低于CPU执行指令的速度，为缓和这一矛盾，在计算机系统中引入了寄存器和高速缓存。


### 1.2.2 寄存器

寄存器是CPU内部的一些小型存储区域，用于暂时存放参与运算的指令、数据和运算结果等内容。

寄存器具有与处理机相同的速度，因此寄存器的访问速度也是最快的，其完全能与CPU协调工作，但价格却十分昂贵，故其容量不可能做得很大。


## 1.3 高速缓存和磁盘缓存

### 1.3.1 高速缓存

高速缓存是现代计算机结构中的一个重要部件，它是介于寄存器和内存之间的存储器，主要用于备份内存中较常用的数据，以减少处理机对内存的访问次数，这样可大幅度地提高程序执行速度。

高速缓存的容量远大于寄存器，而又比内存约小两个到三个数量级，容量一般为几十KB到几MB，访问速度快于内存。

通常，进程的程序和数据存放在内存中，每当要访问它们时，它们才会被临时复制到一个速度较快的高速缓存中。这样，当CPU访问一组特定信息时，须首先检查它是否在高速缓存中
- 如果在，便可直接从中取出并使用，以避免访问内存。
- 否则，就须从内存中读出信息。
例如，大多数计算机系统都有一个指令高速缓存，用来暂存下一条将要执行的指令。如果没有这种指令高速缓存，CPU将会空等若干个时钟周期，直到下一条指令从内存中取出。由于高速缓存的速度越高，价格越贵，故在有的计算机系统中设置了两级或多级高速缓存。紧靠CPU的一级高速缓存的速度最高，但容量最小；二级高速缓存的容量稍大，但速度稍低。


### 1.3.2 磁盘缓存

由于目前磁盘的I/O速度远低于对内存的访问速度，为了缓和两者在速度上的不匹配，特设置了磁盘缓存，主要用于暂时存放频繁使用的一部分磁盘数据，以减少访问磁盘的次数。

但磁盘缓存与高速缓存不同，它本身并不是一种实际存在的存储器，而是利用内存中的部分存储空间，暂时存放从磁盘中读出（或写入）的信息。

内存也可被看作辅存的高速缓存，因为辅存中的数据必须复制到内存方能使用；此外，数据也必须先存在于内存中才能输出到辅存。



# 2. 程序的装入与链接

要在系统中运行用户程序，就必须先将其装入内存中，然后将其转变为一个可以执行的程序，这一过程通常要经过以下3个步骤：
- 编译，由编译程序（compiler）对用户源程序进行编译，形成若干个目标模块（object module）；
- 链接，由链接程序（linker）将编译后形成的一组目标模块以及它们所需要的库函数链接在一起，形成一个 完整的装入模块（load module）；
- 装入，也称为加载，由装入程序（loader）将装入模块装入内存。

图5-3所示为处理用户程序的3个步骤。本节将在介绍这些过程中涉及的地址绑定和内存 保护的基础上，扼要阐述程序（含数据）的链接与装入过程。


![](assets/5-3.png)

## 2.1 地址绑定和内存保护


### 2.1.1 逻辑地址和物理地址

上述步骤中，地址可能有不同的表示形式。
- 源程序中的地址通常用符号表示，如变量count。
- 编译器通常将这些符号地址绑定（bind）到可重定位的地址或相对地址（如从本模块开始的第10个字节）上。
- 链接程序或装入程序再将这些相对地址绑定到绝对地址（如内存的第74 010个字节）。
每次绑定都是从一个地址空间到另一个地址空间的映射。地址绑定通常发生在程序编译时、装入时或运行时，具体的绑定方式详见5.2.2小节。


- CPU生成的地址通常称为逻辑地址（logic address）或相对地址
- 而内存单元看到的地址（即装入内存地址寄存器的地址），通常称为物理地址（physical address）或绝对地址。

在编译时和装入时的地址绑定会生成相同的逻辑地址和物理地址，而执行时的地址绑定则会生成不同的逻辑地址和物理地址。在这种情况下，我们也称逻辑地址为虚拟地址（virtualaddress）。由程序所生成的所有逻辑地址的集合称为逻辑地址空间（logic address space），这些逻辑地址对应的所有物理地址的集合称为物理地址空间（physical address space）。因此，对于执行时的地址绑定方案，逻辑地址空间与物理地址空间是不同的。
<!-- TODO: previous paragrapha -->

### 2.1.2 内存保护

系统不仅需要完成地址变换，还需要保证操作的正确。为了系统操作的正确
- 应保证OS不被用户访问
- 在多用户系统上，还应保证用户进程不会相互影响。
这种保证是用硬件来实现的，因为OS通常不干预CPU对内存的访问（倘若干预，则会导致性能损失）。硬件实现具有多种不同的方式。


首先，需要确保每个进程都有一个单独的内存空间。为了分开内存空间，需要确定一个进程可以访问的合法地址范围，并确保该进程只能访问这些合法地址。系统通过两个寄存器来实现这种保护，这两个寄存器即
- 基地址寄存器（base register）: 基地址寄存器保存最小的合法物理内存地址（基地址）
- 界限寄存器（limitregister）: 界限寄存器指定了合法范围的大小（界限地址）。

内存空间保护的实现是通过CPU硬件对在用户态下产生的物理地址与寄存器的地址进行比较来完成的，即判断“基地址≤物理地址＜（基地址+界限地址）”是否成立。

当在用户态下执行的程序试图访问OS内存或其他用户内存时，其会陷入OS内核，而OS内核则会将其作为致命错误来处理。这种方案可以防止用户程序无意或故意修改OS以及其他用户的代码或数据。

加载基地址寄存器和界限寄存器时必须使用特权指令，由于特权指令只能在内核态下执行，因此只有OS内核才可以加载基地址寄存器和界限寄存器。这种方案允许OS内核修改这两个寄存器的值，而不允许用户程序修改它们。


## 2.2 程序的装入

为了便于读者理解，我们先介绍一个无须进行链接的单个目标模块的装入过程。该目标模块就是装入模块。在将一个装入模块装入内存时，可以有如下3种装入方式。

### 2.2.1 绝对装入方式

用户程序经编译后，将产生绝对地址的目标代码。装入模块被装入内存后，由于程序中的逻辑地址与实际内存地址完全相同，故无须对程序和数据的地址进行修改。

绝对装入方式只能将目标模块装入内存中事先指定的位置，这只适用于单道程序环境

### 2.2.2 可重定位装入方式

把在装入时对目标程序中指令和数据的逻辑地址变换为物理地址的过程，称为重定位。

如果地址变换是在进程装入时一次性完成的，以后不再改变，则称这种重定位方式为静态重定位。


![](assets/5-4.png)

可重定位装入方式可将装入模块装入内存中任何允许的位置，故可用于多道程序环境。但该方式并不允许程序运行时在内存中移动位置。因为程序在内存中的移动，意味着它的物理位置发生了变化，这时必须对程序和数据的地址（绝对地址）进行修改后，程序方能运行。

### 2.2.3 动态运行时装入方式

动态运行时装入方式在把装入模块装入内存后，并不会立即把装入模块中的相对地址变换为绝对地址，而是会把这种地址变换推迟到程序真正要执行时才进行。因此，装入内存后的所有地址都仍是相对地址。这种在运行时进行地址变换的重定位方式称为动态重定位。

> 逻辑地址+重定位寄存器（相对偏移量）=物理地址

## 2.3 程序的链接

源程序经过编译后，可得到一组目标模块。链接程序的功能是将这组目标模块以及它们所需要的库函数，装配成一个完整的装入模块。

在对目标模块进行链接时，根据进行链接的时间的不同，可把链接分成以下3种:

### 2.3.1 静态链接

在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的装配模块，以后不再拆开。我们把这种事先进行链接而以后不再拆开的方式，称为静态链接（static linking）方式。

我们通过一个例子来说明在实现静态链接时应解决的一些问题。在图5-5（a）中给出了经过编译后所得的3个目标模块A、B、C，它们的长度分别为L、M、N

在模块A中有一条语句CALL B，用于调用模块B。在模块B中有一条语句CALL C，用于调用模块C。B和C都属于外部调用符号，在将这几个目标模块装配成一个装入模块时，须解决以下两个问题。
- 修改相对地址。
    
    在由编译程序所产生的所有目标模块中，使用的都是相对地址，它们的起始地址都为0，每个模块中的地址都是相对起始地址计算的。在将它们链接成一个装入模块后，原模块B和C在装入模块中的起始地址不再是0，而分别是L和L+M，故此时须修改模块B和C中的相对地址，即使原模块B中的所有相对地址都加上L，原模块C中的所有相对地址都加上L+M。

- 变换外部调用符号。

    将每个模块中所用的外部调用符号也都变换为相对地址，如把B的起始地址变换为L，把C的起始地址变换为L+M，如图5-5（b）所示。这种先进行链接所形成的一个完整的装入模块，又称为可执行文件。其形成后便通常不再拆开，要运行时可直接将其装入内存。把这种事先进行链接而以后不再拆开的链接方式，称为静态链接方式。


![5-5](assets/5-5.png)

### 2.3.2 装入时动态链接

装入时动态链接（load-time dynamic linking）是指，将用户源程序编译后所得的一组目标模块，在装入内存时，采用边装入边链接的链接方式
> 即在装入一个目标模块时，若发生一个外部模块调用事件，则将引起装入程序找出相应的外部目标模块，并将它装入内存，还要按照图5-5所示的方式修改目标模块中的相对地址。

优点：
- 便于修改和更新

    对于经静态链接装配在一起的装入模块，如果要修改或更新其中的某个目标模块，则要求重新打开装入模块。这不仅是低效的，而且有时是不可能的。若采用动态链接方式，则由于各目标模块是分开存放的，因此要修改或更新各目标模块是一件非常容易143的事。

- 便于实现对目标模块的共享

    在采用静态链接方式时，每个应用模块都必须含有其目标模块的复制版本，而无法实现对目标模块的共享。但采用装入时动态链接方式时，OS很容易将一个目标模块链接到几个应用模块上，实现多个应用程序对该目标模块的共享。


### 2.3.3 运行时动态链接

将对某些模块的链接推迟到程序执行时才进行。亦即，在执行过程中，当发现一个“被调用模块”尚未被装入内存时，立即由OS去找到该模块，将其装入内存，并链接到装入模块上。
> 有点像lazy-load

但是会增加程序运行时的链接时间



# 3. 对换与覆盖

在较小的内存空间运行较大的进程，这些技术被称为内存“扩充”技术。所谓的内存“扩充”，并不是指增加系统的物理内存，而是指在现有的物理内存的基础上扩大内存的使用效率。

## 3.1 多道程序环境下的对换技术

### 3.1.1 对换的引入

所谓“对换”，是指把内存中暂时不能运行的进程或者暂时不用的程序和数据，转移到外存上，以便腾出足够的内存空间，再把已具备运行条件的进程或进程所需要的程序和数据存入内存，进而实现所谓的“对换”。


### 3.1.2 对换的类型

1. 整体对换

    对换是以整个进程为单位的

2. 页面（分段）对换

    对换是以进程的一个“页面”或“分段”为单位而进行的

## 3.2 对换区的管理

### 3.2.1 目标

在具有对换功能的OS中，通常把磁盘空间分为文件区和对换区这两部分。

1. 文件区管理的主要目标

    对文件区管理的主要目标是提高文件存储空间的利用率，然后才是提高对文件的访问速度。因此，对文件区的管理应采取离散分配存储管理方式（具体介绍详见本书第9章）。

2. 对换区管理的主要目标
    
    对对换区进行管理的主要目标是提高进程换入和换出的速度，然后才是提高文件存储空间的利用率。因此，对对换区的管理应采取连续分配存储管理方式


### 3.2.2 数据结构

为了实现对对换区中的空闲盘块的管理，在系统中应配置相应的数据结构，用于记录外存对换区中的空闲盘块的使用情况。

其数据结构的形式，与内存在动态分区分配方式中所用的数据结构相似，即同样可以用空闲分区表或空闲分区链。空闲分区表的每个表目中均应包含两项，即对换区的起始地址及其大小，它们分别用盘块号和盘块数来表示。


### 3.2.3 对换区的分配与回收

由于对换区的分配采用的是连续分配存储管理方式，因而对换区的分配与回收，与采用动态分区方式时的内存分配与回收方法类似。其分配算法可以是首次适应算法、循环首次适应算法或最佳适应算法等。具体的分配与回收操作也与动态分区方式相同，故不再赘述。

<!-- TODO: 数据结构和分配与回收里讲到的东西好像有点陌生 -->

## 3.3 进程的换出与换入

当内核因执行某操作而发现空间不足时，便会调用（或唤醒）对换进程，它的主要任务是实现进程的换出与换入。图5-6所示为对换示意。

![](assets/5-6.png)

### 3.3.1 进程的换出

1. 选择被换出的进程

- 检查所有驻留在内存中的进程，首先选择处于阻塞状态或睡眠状态的进程，当有多个这样的进程时，应当选择优先级最低的进程作为换出进程。
- 在有的系统中，为了防止低优先级进程在被调入内存后很快又被换出，还须考虑进程在内存中的驻留时长。
- 如果系统中已无阻塞进程，而现在的内存空间仍不足以满足需要，则选择优先级最低的就绪进程换出。


2. 换出进程


- 应先申请对换区，若申请成功，就启动磁盘，将该进程的程序和数据传送到磁盘的对换区上。
- 若传送过程未出现错误，则可回收该进程所占用的内存空间，并对该进程的PCB和内存分配表等数据结构做相应的修改。
- 若此时内存中还有可换出的进程，则继续执行换出操作，直到内存中再无阻塞进程为止。

> 选择好换出的进程后，在对进程进行换出时，只能换出非共享的程序和数据段，而对于那些共享的程序和数据段，只要还有进程需要它，就不能被换出。


### 3.3.2 进程的换入

对换进程将定时执行换入操作
- 它首先会查看PCB集合中所有进程的状态，从中找出处于“就绪”状态但已被换出的进程。
- 当有许多这样的进程时，它将选择其中已换出到磁盘上且时间最久（必须大于规定时间，如2s）的进程作为换入进程，并为它申请内存空间。
- 如果申请成功，则可直接将进程从外存换入内存；
- 如果申请失败，则须先将内存中的某些进程换出，腾出足够的内存空间后，再将进程换入。
在对换进程成功地换入一个进程后，若还有可换入的进程，则继续执行换入操作，将其余处于“就绪且换出”状态的进程陆续换入，直到内存中再无处于“就绪且换出”状态的进程为止，或者已无足够的内存来支持换入进程，此时对换进程才会停止换入操作。


由于要交换一个进程需要很多时间，因此，对于提高处理机的利用率而言，它并不是一个非常有效的解决方法。目前用得较多的对换方案是
- 在处理机正常运行时并不启动对换程序
- 但如果发现有许多进程在运行时经常发生缺页，且显现出内存紧张的情况，则启动对换程序，将一部分进程调至外存。如果发现所有进程的缺页率都已明显减少，而系统吞吐量已下降时，则可暂停运行对换程序。

> 缺页是指在计算机的虚拟内存系统中，当程序需要访问的页面（内存块）不在物理内存中时发生的情况。操作系统会将虚拟内存中所需的数据从磁盘（外存）加载到物理内存中，而这个加载过程会导致一定的时间开销。每当发生这种情况时，就称之为“缺页”。


## 3.4 覆盖

覆盖的思想是，在任何时候只在内存中保留所需的指令和数据；当需要其他指令和数据时，它们就会被装入刚刚不需要的指令和数据所占用的内存空间。

覆盖在具体实现时是指，在程序执行过程中，程序的不同部分相互替换。详细来说就是，只在内存中保留那些在任何时候都需要的指令和数据，程序其余的部分（即那些不会同时执行的程序段）则根据它们自身的逻辑结构，使它们共享同一块内存区域。

> 覆盖技术要求程序各模块之间有明确的调用结构。这个工作是程序员完成的，因为只有程序员最了解自己的程序。程序员声明覆盖结构后，OS只是完成覆盖的过程。

覆盖的使用通常局限于微处理机和只有有限物理内存且缺乏先进硬件支持的其他系统。

# 4. 连续分配存储管理方式

该分配方式为一个用户程序分配一个连续的内存空间，即程序中代码或数据的逻辑地址相邻，体现在内存空间中为分配的物理地址相邻。

## 4.1 单一连续分配

在单道程序环境下，早期的存储器管理方式是把内存分为系统区和用户区两部分。系统区仅供OS使用，它通常放在内存的低址部分。而在用户区内存中，仅装有一道用户程序，即整个内存的用户区由该程序独占。这样的存储器分配方式被称为单一连续分配。


## 4.2 固定分区分配

将整个用户空间划分为若干个固定大小的区域（称为分区），并在每个分区中只装入一道作业，这样就形成了最早的、也是最简单的一种可运行多道程序的分区式存储管理方式。

### 4.2.1 分区划分

1. 分区等大小

    即所有的内存分区大小相等。该方法的缺点是缺乏灵活性
    > 由于每个分区的大小固定，必然会造成存储空间的浪费，因而现在已很少将它用于通用的OS中。

2. 分区不等大小

    通常，可把内存划分成含有多个小分区、适量的中等分区及少量的大分区。


### 4.2.2 内存分配

为了便于内存分配，通常将分区按其大小进行排队，并为之建立一张固定分区使用表，其中包括每个分区的起始地址、大小及状态（是否已分配）


## 4.3 动态分区分配

动态分区分配属于可变分区分配，它是根据进程的实际需要，动态地为之分配内存空间的。


### 4.3.1 动态分区分配中的数据结构

1. 空闲分区表

    记录每个空闲分区的情况。每个空闲分区占一个表目，表目中包括分区号、分区大小和分区起始地址等数据项

2. 空闲分区链

    为了实现对空闲分区的分配和链接，在每个分区的头部，设置一些用于控制分区分配的信息和链接各分区所用的前向指针，在每个分区的尾部则设置一个后向指针。通过前、后向指针可将所有的空闲分区链接成一个双向链


![5-9](assets/5-9.png)

### 4.3.2 动态分区分配算法

1. 基于顺序搜索的动态分区分配算法（顺序分配算法）

通常会将系统中的空闲分区链接成一个链，指依次搜索空闲分区链上的空闲分区，以寻找一个大小能满足要求的分区。

- 首次适应算法

分配内存时，从链首开始顺序查找，直至找到一个大小能满足要求的空闲分区为止。然后按照作业的大小，从该分区中划出一块内存空间分配给请求者，余下的空闲分区仍留在空闲链中。若从链首直至链尾都找不到一个能满足要求的分区，则表明系统中已没有足够大的内存分配给该进程，内存分配失败，返回。

首次适应算法倾向于优先利用内存中低址部分的空闲分区，从而保留了高址部分的大空闲分区。

- 循环首次适应算法

循环首次适应算法在为进程分配内存空间时，不再是每次都从链首开始查找，而是从上次找到的空闲分区的下一个空闲分区开始查找，直至找到一个能满足要求的空闲分区，然后从中划出一块与请求的大小相等的内存空间分配给作业。

> 避免首次适应算法中低址部分留下许多很小的空闲分区的缺点

- 最佳适应算法

所谓“最佳”，是指每次为作业分配内存时，总是把能满足要求、又是最小的空闲分区分配给作业，避免“大材小用”。为了加速寻找，最佳适应（best fit，BF）算法要求将所有的空闲分区按其容量以从小到大的顺序，排成一个空闲分区链。这样，第一次找到的、能满足要求的空闲分区，必然是最佳的。
> 因为每次分配后所切割下来的剩余部分总是最小的，这样，在存储器中会留下许多难以利用的碎片

- 最坏适应算法

扫描整个空闲分区表或空闲分区链时，总是会挑选一个最大的空闲区，从中分割一部分存储空间给作业使用，以至于存储器中会缺乏大的空闲分区，故把它称为最坏适应算法。

2. 基于索引搜索的动态分区分配算法（索引分配算法）。

基本思想都是将空闲分区根据分区大小进行分类，对于每类（具有相同大小的）空闲分区，单独设立一个空闲分区链表，并设置一张索引表来管理这些空闲分区链表。在为进程分配空间时，在索引表中查找所需空间大小对应的表项，并从中得到对应的空闲分区链表表头指针，从而实现通过查找得到一个空闲分区。


- 快速适应算法
    - 第一步是根据进程的长度，在索引表中找到能容纳它的最小空闲分区链表；
    - 第二步是从链表中取下第一块进行分配。

该算法在进行空闲分区分配时，不会对任何分区产生分割，因此能保留大的分区，满足对大空间的需求，也不会产生内部碎片。
> 典型的以空间换时间的做法


- 伙伴系统

    规定，无论已分配分区还是空闲分区，其大小均为2的k次幂，k为正整数。对于具有相同大小的所有空闲分区，为它们单独设立一个空闲分区双向链表。当需要为进程分配一个长度为n的存储空间时
    - 首先计算一个i值，使$2_{i-1}＜n≤2_i$，然后在空闲分区大小为$2_i$的空闲分区链表中查找。
    - 若能找到，则把该空闲分区分配给进程。
    - 否则，表明大小为$2_i$的空闲分区已经耗尽，须在分区大小为$2_{i+1}$的空闲分区链表中接着查找。
    - 若存在大小为$2_{i+1}$的一个空闲分区，则把该空闲分区分为相等的两个分区，这两个分区称为“一对伙伴”
        - 其中的一个分区用于分配
        - 而把另一个分区加入大小为2i的空闲分区链表中
    - 若不存在，则需要继续查找，如此循环直至找到为止。
    
> 回收分区时也可能要进行多次合并。


- 哈希算法 

构造一张以空闲分区大小为关键字的哈希表，该表的每个表项均记录了一个对应的空闲分区链表表头指针。当进行空闲分区分配时，根据所需空闲分区大小，通过哈希函数计算得到哈希表中的位置，从中得到相应的空闲分区链表，最终实现最佳分配策略。


### 4.3.3  分区的分配与回收

1. 分配内存

分配内存是指系统利用某种分配算法，从空闲分区链表中找到所需大小的分区。
- 设请求的分区大小为u.size，表中每个空闲分区的大小为m.size。
- 若m.size-u.size≤size（size是事先规定的不再切割的剩余分区的大小），则说明多余部分太小，可不再切割，并将整个分区分配给请求者。
- 否则（即多余部分超过size），从该分区中按请求的大小，划分出一块内存空间并分配出去，余下的部分仍留在空闲分区链表中；
- 然后，将分配区的起始地址返回给调用者。图5-11所示为内存分配流程。

![5-11](assets/5-11.png)

2. 回收内存

当进程运行完毕而须释放内存时，系统会根据回收区的起始地址，从空闲分区链表中找到相应的插入点，此时可能会出现以下四种情况之一:

- 回收区与插入点的前一个空闲分区F1相邻接

    此时应将回收区与插入点的前一分区合并，不必为回收分区分配新表项，而只须修改其前一分区F1的大小。

- 回收区与插入点的后一个空闲分区F2相邻接

    此时可将两分区合并，形成新的空闲分区，但须将回收区的起始地址作为新空闲区的起始地址，分区大小为两者之和。

- 回收区同时与插入点的前、后两个分区邻接

    此时将三个分区合并，使用F1的表项和起始地址，取消F2的表项，分区大小为三者之和。

- 回收区既不与F1邻接，也不与F2邻接。

    这时应为回收区单独建立一个新表项，填写回收区的起始地址和大小，并根据其起始地址将其插入空闲分区链表中的适当位置。


![5-12](assets/5-12.png)



## 4.4 动态重定位分区分配

### 4.4.1 紧凑


连续分配方式的一个重要特点是，一个系统或用户程序必须被装入一个连续的内存空间中。当一台计算机运行了一段时间后，它的内存空间将会被分割成许多小分区，而缺乏大的空闲空间。这种不能被利用的小分区，就是前面已提及的“碎片”，也称为“零头”。

将内存中的所有作业进行移动，使它们全都相邻接。这样，即可把原来分散的多个小分区拼接成一个大分区，这时就可以把一个作业装入该分区了。这种通过移动内存中作业的位置，把原来分散的多个小分区拼接成一个大分区的方法，称为“紧凑”



![5-14](assets/5-14.png)

然“紧凑”能获得大的空闲空间，但也带来了新的问题，即经过紧凑后的用户程序在内存中的位置发生了变化，此时若不对程序和数据的地址加以修改（变换），则程序必将无法执行。为此，在每次“紧凑”后，都必须对移动后的程序或数据进行重定位。下面要介绍的动态重定位方法，可以很好地解决此问题。

### 4.4.2 动态重定位

在5.2.2小节中所介绍的动态运行时装入方式中，作业装入内存后的所有地址仍然是相对地址，而将相对地址变换为物理地址的工作，被推迟到程序指令要真正执行时进行。

为使地址的变换不会影响指令的执行速度，必须有硬件地址变换机构的支持，即须在系统中增设一个重定位寄存器，用它来存放程序（数据）在内存中的起始地址。

程序在执行时，真正访问的内存地址是相对地址与重定位寄存器中的地址相加而形成的。

图5-15所示为动态重定位的实现原理。地址变换过程是在程序执行期间随着对每条指令或数据的访问自动进行的，故称之为动态重定位。


![5-15](assets/5-15.png)

当系统对内存进行了“紧凑”，而使若干程序从内存的某处移至另一处时，无须对程序做任何修改，只要用该程序在内存中的新起始地址去置换原来的起始地址即可。(即修改重定位寄存器的值)

### 4.4.3 动态重定位分区分配算法

动态重定位分区分配算法与动态分区分配算法基本相同，差别仅在于：在这种分配算法中增加了“紧凑”功能。
- 当该算法不能找到一个足够大的空闲分区以满足用户需求时，如果所有小的空闲分区的容量总和大于或等于用户的要求，则此时便须对内存进行“紧凑”，并将“紧凑”后所得的大空闲分区分配给用户。
- 如果所有小的空闲分区的容量总和仍小于用户的要求，则返回分配失败信息。

图5-16所示为动态重定位分区分配算法流程图。

![5-16](assets/5-16.png)



# 5. 分页存储管理方式

连续分配方式会形成许多“碎片”，虽然可以通过“紧凑”方法将许多碎片拼接成可用的大块空间，但须为之付出很大的开销。

如果允许将一个进程直接分散地装入许多不相邻接的分区中，则可充分地利用内存空间而无须再进行“紧凑”。

基于这一思想而产生了离散分配存储管理方式（简称离散分配方式）。

根据在离散分配时所分配地址空间的基本单位的不同，可将离散分配方式分为以下3种。
- 分页存储管理方式

    - 将用户程序的地址空间分为若干个固定大小的区域，称之为“页”或“页面”。典型的页面大小为1KB、2KB、4KB等。
    - 相应地，也将内存空间分为若干个物理块或页框（frame），页和块的大小相同。这样就可以将用户程序的任一页放入任一物理块中，进而实现离散分配。

- 分段存储管理方式

    - 这是为了满足用户要求而形成的一种离散分配方式。
    - 它把用户程序的地址空间分为若干个大小不同的段，每段可定义一组相对完整的信息。
    - 在存储器分配时，以段为单位，这些段在内存中可以不相邻接，因此也同样实现了离散分配。

- 段页式管理存储机制

    分页和分段两种存储管理方式相结合的产物，它同时具有两者的优点，是目前应用较广泛的一种存储管理方式。

## 5.1 分页存储管理的基本方法

### 5.1.1 页面和物理快

1. 页面

- 分页存储管理将进程的地址空间分成若干个页，并为每页加以编号，从0开始，如第0页、第1页等。
- 相应地，也把内存空间分成若干个块，同样也为它们加以编号，如0#块、1#块等。
- 在为进程分配内存时，以块为单位，将进程中的若干个页分别装入多个可以不相邻接的物理块中。
- 由于进程的最后一页经常装不满一块，进而形成了不可利用的碎片，称之为“页内碎片”或“内碎片”。


2. 页面大小

在分页系统中
- 若选择过小的页面大小
    - 则虽然可以减小内部碎片，起到减少内部碎片总空间的作用，有利于内存利用率的提高
    - 但是会造成每个进程占用较多的页面，从而导致进程的页表过长，占用大量内存；此外，还会降低页面换入/换出的效率。
- 如果选择过大的页面大小
    - 则虽然可以减少页表的长度，以及提高页面换入/换出的效率
    - 但是又会使页内碎片增大。

因此，页面的大小应选择得适中，且页面大小应是2的幂，通常为1KB、2KB、4KB、8KB。


### 5.1.2 地址结构


![5-17](assets/5-17.png)

- 前一部分为页号P
- 后一部分为位移量W，即页内地址

图5-17中的地址长度为32位，其中0～11位为页内地址，即每页的大小为4KB；12～31位为页号，地址空间最多允许有1M页。

### 5.1.3 页表

在分页系统中，允许将进程的各个页离散地存储在内存的任一物理块中，为能在内存中找到每个页面所对应的物理块，系统又为每个进程建立了一张页面映像表，简称页表。

在进程地址空间内的所有页（0～n），依次在页表中有一页表项，其中记录了相应页在内存中对应的物理块号，如图5-18所示的中间部分。

在配置了页表后，当进程在执行时，通过查找该表即可找到每页在内存中的物理块号。由此可见，页表的作用是实现从页号到物理块号的地址映射。


![5-18](assets/5-18.png)

会在页表的表项中设置一个存取控制字段，用于对该存储块中的内容加以保护。
- 当存取控制字段仅有一位时，可用于规定该存储块中的内容是允许读/写，还是只读；
- 若存取控制字段为二位，则可用于规定读/写、只读和只执行等存取方式。
> 如果有一进程试图去写一个只允许读的存储块，则会引起OS的一次中断。
- 如果要利用分页系统去实现虚拟存储器，则还须增设一个数据项，这一点将在第6章后面做详细介绍。


## 5.2 地址变换机构

基本任务是实现从逻辑地址到物理地址的变换。

由于页大小等于块大小，因此页内地址和块内地址是一一对应的，无须再进行变换。

由此可知，地址变换机构的任务实际上只是将逻辑地址中的页号变换为内存中的物理块号。又因为页表的作用就是用于实现从页号到物理块号的变换，因此，地址变换是借助页表来完成的。

### 5.2.1 基本的地址变换机构

对程序和数据的地址进行变换，由于它执行的频率非常高，每条指令的地址都需要进行变换，因此需要利用硬件来实现。

页表功能是由一组专门的寄存器来实现的，一个页表项用一个寄存器。页表大多驻留在内存中。在系统中只设置一个页表寄存器（page-table register，PTR），在其中存放页表（在内存中）的起始地址和页表长度。平时，在进程未执行时，页表的起始地址和页表长度存放在本进程的PCB中。当调度程序调度到某进程时，才将这两个数据装入页表寄存器中。因此，在单处理机环境下，虽然系统中可以运行多个进程，但只需要一个页表寄存器

当进程要访问某个逻辑地址中的数据时
- 分页地址变换机构会自动将有效地址（逻辑地址）分为页号和页内地址两部分，再以页号为索引去检索页表
- 查找操作由硬件执行。在执行检索之前，先将页号与页表长度进行比较
    - 如果页号大于或等于页表长度，则表示本次所访问的地址已超越进程的地址空间。于是，这一错误将被系统发现，并产生一个地址越界中断。
    - 若未出现越界错误，则将页表起始地址与“页号和页表项长度的乘积”相加，便可得到该表项在页表中的位置，于是可以从中得到该页的物理块号，然 后将之装入物理地址寄存器中。与此同时，再将有效地址寄存器中的页内地址送入物理地址寄存器的块内地址字段中。这样便完成了从逻辑地址到物理地址的变换。图5-19所示为分页系统的地址变换机构。



![5-19](assets/5-19.png)


### 5.2.2 具有快表的地址变换机构

页表是存放在内存中的，这使CPU在每次存取一个数据时都要访问内存两次
- 第一次是访问内存中的页表，从中找到指定页的物理块号，再将块号与页内偏移量拼接，以形成物理地址
- 第二次访问是从第一次所得地址中获得所需数据（或向此地址中写入数据）

为了提高地址变换速度，可在地址变换机构中增设一个具有并行查寻能力的高速缓冲寄存器，称为“联想寄存器”（associative memory）或“快表”，用以存放当前访问的那些页表项。此时的地址变换过程是：
- 在CPU给出有效地址后，由地址变换机构自动地将页号送入高速缓冲寄存器，并将此页号与高速缓存寄存器中的所有页号进行比较
- 若其中有与此页号相匹配的页号，则表示所要访问的页表项在快表中。于是，可直接从快表中读出该页所对应的物理块号b，并将其送到物理地址寄存器中。
- 若在快表中未找到对应的页表项，则还须再访问内存中的页表，直至找到后，把从页表项中读出的物理块号送到地址寄存器
- 同时，再将此页表项存入快表的一个寄存器单元中，亦即重新修改快表。
> 但如果快表已满，则OS必须找到一个老的且已被认为是不再需要的页表项，并将它换出。



### 5.2.3 引入快表后的内存有效访问时间


$$内存的有效访问时间EAT(Effective Access Time) = 发出逻辑地址请求 \to 经过地址变换找到实际无物理地址 \to 取出数据$$ 

假设访问内存的时间为$t$

- 对于没有引入快表时的有效访问时间

$$ETA = t  + t = 2t $$

- 对于快表

$a$为命中率，$b$为查找块表所需时间

$$ETA = a \cdot (b + t) + (1 - a)(b + t + t ) $$


## 5.3 两级页表和多级页表

现代的大多数计算机系统，都支持非常大的逻辑地址空间（$2_{32}～2_{64}$）。在这样的环境下，页表变得非常大，且要占用相当大的内存空间。页表空间而且还要求是连续的

我们可以采用下述两个方法来解决这一问题：
- 对于页表所需的内存空间，可采用离散分配方式，以解决难以找到一块连续的大内存空间的问题；
- 只将当前需要的部分页表项调入内存，其余的页表项仍驻留在磁盘上，需要时再调入。

### 5.3.1 两级页表

针对难以找到连续的大内存空间来存放页表的问题，可利用将页表进行分页的方法，使每个页面的大小与内存物理块的大小相同，并为它们编号，依次编为0#页、1#页……n#页，然后离散地将各个页面分别存放在不同的物理块中。同样，也要为离散分配的页表再建立一张页表，称之为外层页表（outer page table），在每个页表项中记录页表页面的物理块号。



![5-21](assets/5-32.png)

上述对页表施行离散分配的方法，虽然解决了对大页表无需大片连续存储空间的问题，但并未解决用较少的内存空间去存放大页表的问题。
> 能够用较少的内存空间存放页表的唯一方法是，仅把当前需要的一批页表项调入内存，以后再根据需要陆续调入。在采用两级页表结构的情况下，对于正在运行的进程，必须将其外层页表调入内存，而对于页表则只须调入一页或几页。为了表征某页的页表是否已经调入内存，还应在外层页表项中增设一个状态位S，其值若为0，则表示该页表分页不在内存中，否则表示该页表分页已调入内存。进程运行时，地址变换机构根据逻辑地址中的P1查找外层页表；若所找到的页表项中的状态位为0，则产生一个中断信号，并请求OS将该页表分页调入内存。关于请求调页的详细情况，将在第6章（虚拟存储器）中进行介绍。

### 5.3.2 多级页表

类似于两级页表，增加嵌套的层数，以至于可以装下所需的页表


## 5.4 反置页表

### 5.4.1 引入

分页系统中，为每个进程配置了一张页表，进程逻辑地址空间中的每一页，在页表中都对应有一个页表项。在现代计算机系统中，通常允许一个进程的逻辑地址空间非常大，因此就需要有许多的页表项，它们会占用大量的内存空间。

为了减少页表占用的内存空间，引入了反置页表。一般页表的页表项是按页号进行排序的，页表项中的内容是物理块号。

而反置页表（inverted page table）则是为每个物理块设置一个页表项，并将它们按物理块的编号进行排序，其中的内容则是页号和其所隶属进程的标识符。

### 5.4.2 地址变换

在利用反置页表进行地址变换（见图5-23）时，会根据进程标识符pid和页号p检索反置页表。
- 如果检索到了与之匹配的页表项，则该表项的序号i便是该页所在的物理块号，可用该块号i与页内地址d一起构成物理地址送往内存地址寄存器。
- 若检索了整个反置页表都未找到匹配的页表项，则表明此页尚未装入内存。 
    - 对于不具有请求调页功能的存储器管理系统，此时则显示地址出错。
    - 对于具有请求调页功能的存储器管理系统，此时则产生请求调页中断，系统将把此页调入内存。


![5-23](assets/5-23.png)



# 6. 分段存储管理方式

## 6.1 分段存储管理方式的引入

### 6.1.1 方便编程

用户把自己的作业按照逻辑关系划分为若干个段，每个段都从0开始编址，并且有自己的名字和长度。因此，程序员们都迫切地需要访问的逻辑地址是由段名（段号）和段内偏移量（段内地址）决定的，这不仅可以方便程序员编程，也可使程序非常直观、更具可读性。

### 6.1.2 信息共享

实现对程序和数据的共享，是以信息的逻辑单位为基础的，例如，共享某个过程、函数或文件。
- 分页系统中的“页”只是存放信息的物理单位（块），并无完整的逻辑意义，这样，一个可被共享的过程往往可能需要占用数十个页面，这为实现共享增加了难度。
- 如前所述，段可以是信息的逻辑单位，因此，我们可以为该被共享过程建立一个独立的段，这就极大地简化了共享的实现。

### 6.1.3 信息保护

信息保护同样是以信息的逻辑单位为基础的，而且经常以一个过程、函数或文件为基本单位进行保护。

### 6.1.4 动态链接

动态链接要求的是以目标程序（即段）为链接的基本单位，因此，分段存储管理方式非常适用于动态链接。

### 6.1.5 动态增长

内存管理系统根据进程对段的需求，动态地调整每个段的大小。


## 6.2 分段系统的基本原理

### 6.2.1 分段

在分段存储管理方式中，作业的地址空间被划分为若干段
- 每个段都定义了一组逻辑信息，如有主程序段MAIN、子程序段X、数据段D及栈段S等
- 每个段都有自己的名字。
- 每个段都从0开始编址，并采用一段连续的地址空间。
- 段的长度由相应的逻辑信息组的长度决定，因此各段的长度并不相等。
- 整个作业的地址空间，由于被分成了多个段，因此呈现出了二维特性，亦即，每个段既包含了一部分地址空间，又标志了逻辑关系。段的逻辑地址由段号（段名）和段内地址所组成。分段地址中的地址具有图5-24所示的结构。

![5-24](assets/5-24.png)

### 6.2.2 段表

在系统中（类似于分页系统）须为每个进程建立一张段映射表，简称“段表”。
- 每个段在表中均占有一个表项，其中记录了该段在内存中的起始地址和段的长度，如图5-25所示。
- 段表可以存放在一组寄存器中，以提高地址变换速度，但更常见的方法是将段表存放在内存中。
- 在配置了段表后，执行中的进程可通过查找段表来找到每个段所对应的内存区。
可见，段表是用于实现从逻辑段到物理内存区映射的。

![5-25](assets/5-25.png)


### 6.2.5 地址变换机构

为了实现进程从逻辑地址到物理地址的变换功能，在系统中设置了段表寄存器，用于存放段表起始地址和段表长度TL。

在进行地址变换时，系统将逻辑地址中的段号S与段表长度TL进行比较。
- 若S＞TL，则表示段号太大，访问越界，于是产生越界中断信号。
- 若未越界，则根据段表起始地址和该段的段号，计算出该段对应段表项的位置，从中读出该段在内存中的起始地址。

然后，再检查段内地址d是否超过该段的段长SL。
- 若超过，即d＞SL，则同样产生越界中断信号。
- 若未越界，则将该段的起始地址d与段内地址相加，即可得到要访问的内存物理地址。


> 像分页系统一样，当段表放在内存中时，每当要访问一个数据时，都须访问两次内存，解决的方法同分页系统类似，也增设一个联想存储器，用于保存最近常用的段表项。

### 6.2.6 分页和分段的主要区别

分页和分段系统有许多相似之处。例如，两者都采用离散分配方式，且都通过地址映射机构实现地址变换。但在概念上，两者完全不同，主要表现在下列3个方面。
- 页是信息的物理单位

    - 采用分页存储管理方式是为了实现离散分配方式，以消减内存的外零头，提高内存的利用率。
    - 分段存储管理方式中的段，则是信息的逻辑单位，它通常包含的是一组意义相对完整的信息。分段的目的主要在于能更好地满足用户的需要。

- 页的大小固定且由系统决定
    
    段的长度则不固定，其取决于用户所编写的程序，通常由编译程序在对源程序进行编译时根据信息的性质来划分。

- 分页的用户程序地址空间是一维的

    分页完全是系统的行为，故在分页系统中，用户程序的地址属于单一的线性地址空间，程序员只须利用一个标识符即可表示一个地址。而分段是用户的行为，故在分段系统中，用户程序的地址空间是二维的，程序员在标志一个地址时，既须给出段名，又须给出段内地址。

## 6.3 信息共享

分段系统的一个突出优点是易于实现段的共享，即允许若干个进程共享一个或多个分段，且对段的保护也十分简单易行。

在分页系统中，代码和数据都以页面为单位进行管理。如果共享代码区域（editor的代码段）占用了40个页面，那么每个用户的页表中都必须包含40个页表项。这些页表项会将虚拟页面映射到相同的物理页面（21#至60#），以实现共享。因此，对于40个用户，系统需要维护40 × 40 = 1600个页表项来指向共享的代码页面。

在分段系统中，整个代码区域是作为一个段来管理的，每个用户只需在段表中设置一个段表项，用于指向共享的代码段起始地址。这样，40个用户只需40个段表项，远少于分页系统中的1600个页表项。段表的大小和复杂度明显降低。


# 7. 段页式存储管理方式

- 分页系统以页面为内存分配的基本单位，能有效地提高内存利用率；
- 而分段系统则以段为内存分配的基本单位，能更好地满足用户多方面的需要。

如果能对两种存储管理方式“各取所长”，则可形成一种新的存储管理方式——段页式存储管理方式。这种新的管理方式
- 既具有分段系统的便于实现、分段可共享、易于保护、可动态链接等一系列优点
- 又能像分页系统那样很好地解决内存分配中的外部碎片问题。

## 7.1 基本原理

页式存储管理方式的基本原理，是分段和分页原理的结合，即先将用户程序分成若干段，再把每段分成若干页，并为每一个段赋予一个段名。图5-29（a）所示为作业地址空间结构。该作业有3个段，主程序段、子程序段和数据段，页面大小为4KB。在段页式存储管理方式中，地址结构由段号、段内页号及页内地址这3部分组成，如图5-29（b）所示。



![5-29](assets/5-29.png)

在段页式存储管理方式下，为了实现从逻辑地址到物理地址的变换，系统中需要同时配置段表和页表。段表的内容与分段系统略有不同，它不再是内存起始地址和段长，而是页表起始地址和页表长度。图5-30所示为利用段表和页表进行从用户地址空间到物理（内存）地址空间的映射。


![5-30](assets/5-30.png)


## 7.2 地址变换过程

在段页式存储管理方式下，为了便于实现地址变换，
- 须为系统配置一个段表寄存器，其中存放段表起始地址和段长TL。在进行地址变换时
- 首先比较段号S与段长TL。若S＜TL，则表示未越界
- 于是利用段表起始地址和段号来求出该段所对应的段表项在段表中的位置，从中得到该段的页表起始地址，并利用逻辑地址中的段内页号P来获得对应页的页表项位置，从中读出该页所在的物理块号b，再利用物理块号b和页内地址来构成物理地址。



![5-31](assets/5-31.png)

在段页式存储管理方式下，为了获得一条指令或数据，须三次访问内存
- 第一次访问是访问内存中的段表，从中取得页表起始地址
- 第二次访问是访问内存中的页表，从中取得该页所在的物理块号，并利用该物理块号与页内地址来一起构成指令或数据的物理地址
- 第三次访问才是真正地从第二次访问所得的地址中取出指令或数据。

显然，这使访问内存的次数增加了近两倍。为了提高执行速度，在地址变换机构中增设一个高速缓冲寄存器。它的基本原理与分页及分段的情况相似



# 8. 本章小结

本章首先介绍了存储器管理的背景知识，包括
- 存储器的层次结构
- 程序的装入与链接
- 对换与覆盖等内容；

其次，介绍了连续分配方式，其中重点介绍了
- 动态分区分配
- 动态重定位分区分配；

再次，详细介绍了离散分配存储管理方案中的
- 分页
- 分段
- 段页式存储管理方式；


最后，以IA-32架构和x86-64架构为例，说明了目前个人计算机OS的内存管理策略。不同的存储管理方式在许多方面都存在着不同，在比较不同的存储管理方式时，需要综合考虑如下几点：硬件支持、性能、碎片、重定位、对换、共享和保护。
<!-- TODO: 带了解 -->

